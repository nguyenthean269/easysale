import os
from dotenv import load_dotenv
from langchain_groq import ChatGroq
import re
import time

class GroqChat:
    def __init__(self, model="llama-3.3-70b-versatile", max_tokens=1000, temperature=0.7, n=1, top_p=0.9, stream=False, max_history_length=10, response_format=None):
        # Load bi·∫øn m√¥i tr∆∞·ªùng t·ª´ .env
        load_dotenv()
        self.api_key = os.getenv("GROQ_API_KEY")
        
        if not self.api_key:
            raise ValueError("‚ùå GROQ_API_KEY kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y. H√£y ki·ªÉm tra l·∫°i t·ªáp .env!")
        
        # Kh·ªüi t·∫°o m√¥ h√¨nh Llama t·ª´ Groq
        self.llm = ChatGroq(
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            n=n,
            stream=stream,
            response_format=response_format
        )
        
        # L∆∞u tr·ªØ l·ªãch s·ª≠ h·ªôi tho·∫°i
        self.conversation_history = []
        self.max_history_length = max_history_length
    
    @staticmethod
    def load_prompt(path):
        """
        ƒê·ªçc n·ªôi dung c·ªßa t·ªáp prompt.
        """
        with open(path, "r", encoding="utf-8") as f:
            return f.read().strip()
    
    def chat(self, system_input, user_input):
        start = time.time()
        """
        G·ª≠i c√¢u h·ªèi ƒë·∫øn Groq LLM v√† nh·∫≠n ph·∫£n h·ªìi, duy tr√¨ l·ªãch s·ª≠ h·ªôi tho·∫°i v·ªõi gi·ªõi h·∫°n.
        """
        # Th√™m c√¢u m·ªõi v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i
        self.conversation_history.append(("user", user_input))
        
        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng tin nh·∫Øn trong l·ªãch s·ª≠
        if len(self.conversation_history) > self.max_history_length * 2:
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]

        messages = [("system", system_input)] + self.conversation_history
        
        try:
            response = self.llm.invoke(messages)
            self.conversation_history.append(("assistant", response.content))

            end = time.time()
            print(end - start)

            return GroqResponse(response.content)
        except Exception as e:
            return GroqResponse(f"‚ùå L·ªói t·ª´ Groq API: {e}")


    def chat_stream(self, system_input, user_input):
        """
        Tr·∫£ v·ªÅ ph·∫£n h·ªìi t·ª´ Groq LLM d∆∞·ªõi d·∫°ng stream.
        """
        self.conversation_history.append(("user", user_input))

        if len(self.conversation_history) > self.max_history_length * 2:
            self.conversation_history = self.conversation_history[-self.max_history_length * 2:]

        messages = [("system", system_input)] + self.conversation_history

        try:
            # üëá D√πng stream thay v√¨ invoke
            stream = self.llm.stream(messages)
            for chunk in stream:
                # chunk l√† BaseMessage => chunk.content l√† ph·∫ßn text
                yield chunk.content
        except Exception as e:
            yield f"\n‚ùå L·ªói khi stream t·ª´ Groq: {str(e)}"


    def clear_history(self):
        """
        X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i.
        """
        self.conversation_history = []
    
class GroqResponse:
    def __init__(self, content):
        self.content = content
    
    def clean(self):
        """
        Lo·∫°i b·ªè kho·∫£ng tr·∫Øng d∆∞ th·ª´a t·ª´ response.
        """
        self.content = re.sub(r"<think>.*?</think>", "", self.content, flags=re.DOTALL)
        self.content = self.content.replace("```json", "").replace("```", "").replace("\xa0", " ").strip()
        return self.content
    
    def __str__(self):
        return self.content
