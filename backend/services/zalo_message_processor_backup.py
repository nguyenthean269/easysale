"""
Zalo Message Processor Service
Service x·ª≠ l√Ω tin nh·∫Øn t·ª´ Zalo ƒë·ªãnh k·ª≥ 10 ph√∫t m·ªôt l·∫ßn
"""

import os
import time
import threading
import logging
import json
import argparse
from datetime import datetime
from typing import List, Dict, Optional
from groq import Groq
from dotenv import load_dotenv
from flask import Flask
from flask_sqlalchemy import SQLAlchemy
from utils.property_service_sql import PropertyService

# Load environment variables
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '.env'))

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Debug environment variables
logger.info("üîß Environment variables loaded:")
logger.info(f"DB_CHAT_HOST: {os.getenv('DB_CHAT_HOST', 'NOT_SET')}")
logger.info(f"DB_CHAT_PORT: {os.getenv('DB_CHAT_PORT', 'NOT_SET')}")
logger.info(f"DB_CHAT_USER: {os.getenv('DB_CHAT_USER', 'NOT_SET')}")
logger.info(f"DB_CHAT_PASSWORD: {'SET' if os.getenv('DB_CHAT_PASSWORD') else 'NOT_SET'}")
logger.info(f"DB_CHAT_NAME: {os.getenv('DB_CHAT_NAME', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_HOST: {os.getenv('DB_WAREHOUSE_HOST', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_PORT: {os.getenv('DB_WAREHOUSE_PORT', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_USER: {os.getenv('DB_WAREHOUSE_USER', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_PASSWORD: {'SET' if os.getenv('DB_WAREHOUSE_PASSWORD') else 'NOT_SET'}")
logger.info(f"DB_WAREHOUSE_NAME: {os.getenv('DB_WAREHOUSE_NAME', 'NOT_SET')}")

# T·∫°o Flask app cho zalo_messages database
zalo_app = Flask(__name__)
zalo_app.config['SQLALCHEMY_DATABASE_URI'] = f"mysql://{os.getenv('DB_CHAT_USER', 'easychat')}:{os.getenv('DB_CHAT_PASSWORD', '')}@{os.getenv('DB_CHAT_HOST', '103.6.234.59')}:{os.getenv('DB_CHAT_PORT', '6033')}/{os.getenv('DB_CHAT_NAME', 'zalo_messages')}"
zalo_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
zalo_db = SQLAlchemy(zalo_app)

# T·∫°o Flask app cho warehouse database
warehouse_app = Flask(__name__)
warehouse_app.config['SQLALCHEMY_DATABASE_URI'] = f"mysql://{os.getenv('DB_WAREHOUSE_USER', 'root')}:{os.getenv('DB_WAREHOUSE_PASSWORD', '')}@{os.getenv('DB_WAREHOUSE_HOST', '103.6.234.59')}:{os.getenv('DB_WAREHOUSE_PORT', '6033')}/{os.getenv('DB_WAREHOUSE_NAME', 'warehouse')}"
warehouse_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
warehouse_db = SQLAlchemy(warehouse_app)

class ZaloMessageProcessor:
    """Service x·ª≠ l√Ω tin nh·∫Øn Zalo ƒë·ªãnh k·ª≥"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o service"""
        # Groq client
        self.groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))
        
        # Service control
        self.is_running = False
        self.thread = None
        
        # L·∫•y interval t·ª´ environment variable (ƒë∆°n v·ªã ph√∫t)
        schedule_minutes = int(os.getenv('ZALO_MESSAGE_PROCESSOR_SCHEDULE', '10'))
        self.interval = schedule_minutes * 60  # Chuy·ªÉn t·ª´ ph√∫t sang gi√¢y
        self.schedule_enabled = schedule_minutes > 0  # Ch·ªâ enable n·∫øu > 0
        
        # Unit type mapping t·ª´ name sang id
        self.unit_type_mapping = {
            'ƒê∆°n l·∫≠p': 1,
            'Song l·∫≠p': 2,
            'T·ª© l·∫≠p': 3,
            'T·ª© l·∫≠p c·∫°nh g√≥c': 4,
            'Shophouse': 5,
            'Studio': 6,
            '1PN': 7,
            '1PN+': 8,
            '2PN1WC': 9,
            '2PN2WC': 10,
            '3PN': 11,
            'ƒê∆°n l·∫≠p c·∫°nh g√≥c': 12
        }
        
        logger.info(f"ZaloMessageProcessor initialized (schedule: {self.interval//60} minutes, enabled: {self.schedule_enabled})")
    
    def get_zalo_db_connection(self):
        """T·∫°o k·∫øt n·ªëi database zalo_messages v·ªõi retry mechanism"""
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            try:
                logger.info(f"Attempting to connect to zalo_messages database... (attempt {attempt + 1}/{max_retries})")
                
                with zalo_app.app_context():
                    # S·ª≠ d·ª•ng SQLAlchemy engine v·ªõi connection pooling
                    connection = zalo_db.engine.connect()
                    logger.info("‚úÖ Zalo database connection successful")
                    return connection
                    
            except Exception as e:
                logger.error(f"‚ùå Zalo database connection error (attempt {attempt + 1}): {e}")
                logger.error(f"Error type: {type(e)}")
                
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    logger.error("‚ùå Failed to connect to zalo database after all retries")
                    return None
    
    def get_warehouse_db_connection(self):
        """T·∫°o k·∫øt n·ªëi database warehouse v·ªõi retry mechanism"""
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            try:
                logger.info(f"Attempting to connect to warehouse database... (attempt {attempt + 1}/{max_retries})")
                
                with warehouse_app.app_context():
                    # S·ª≠ d·ª•ng SQLAlchemy engine
                    connection = warehouse_db.engine.connect()
                    logger.info("‚úÖ Warehouse database connection successful")
                    return connection
                    
            except Exception as e:
                logger.error(f"‚ùå Warehouse database connection error (attempt {attempt + 1}): {e}")
                logger.error(f"Error type: {type(e)}")
                
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    logger.error("‚ùå Failed to connect to warehouse database after all retries")
                    return None
    
    def get_unprocessed_messages(self, limit: int = 20) -> List[Dict]:
        """
        L·∫•y danh s√°ch tin nh·∫Øn ch∆∞a x·ª≠ l√Ω t·ª´ b·∫£ng received_messages
        
        Args:
            limit: S·ªë l∆∞·ª£ng tin nh·∫Øn t·ªëi ƒëa c·∫ßn l·∫•y
            
        Returns:
            List c√°c tin nh·∫Øn ch∆∞a x·ª≠ l√Ω
        """
        try:
            logger.info("üîç Starting to fetch unprocessed messages...")
            
            # Retry logic cho connection
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    logger.info(f"üîÑ Attempt {attempt + 1}/{max_retries}")
                    
                    with zalo_app.app_context():
                        logger.info("üì° Zalo app context created")
                        connection = self.get_zalo_db_connection()
                        if not connection:
                            logger.error("‚ùå No database connection available")
                            continue
                        
                        logger.info("üìä Executing query to fetch messages...")
                        from sqlalchemy import text
                        
                        query = text("""
                        SELECT id, session_id, config_id, sender_id, sender_name, 
                               content, thread_id, thread_type, received_at, 
                               status_push_kafka, status_push_warehouse, reply_quote
                        FROM received_messages 
                        WHERE status_push_warehouse = 'NOT_YET' 
                        ORDER BY received_at ASC 
                        LIMIT :limit
                        """)
                        
                        logger.info(f"üîç Query: {query}")
                        logger.info(f"üîç Limit: {limit}")
                        
                        result = connection.execute(query, {"limit": limit})
                        logger.info("‚úÖ Query executed successfully")
                        
                        messages = []
                        for row in result:
                            messages.append(dict(row._mapping))
                        
                        logger.info(f"‚úÖ Found {len(messages)} unprocessed messages")
                        return messages
                        
                except Exception as e:
                    logger.error(f"‚ùå Attempt {attempt + 1} failed: {e}")
                    if attempt < max_retries - 1:
                        logger.info(f"üîÑ Retrying in 2 seconds...")
                        time.sleep(2)
                    else:
                        raise e
                        
        except Exception as e:
            logger.error(f"‚ùå Error fetching messages after {max_retries} attempts: {e}")
            logger.error(f"‚ùå Error type: {type(e)}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return []
    
    def get_property_tree_for_prompt(self, root_id: int = 1) -> str:
        """
        L·∫•y property tree cho prompt
        
        Args:
            root_id (int): ID c·ªßa root group (m·∫∑c ƒë·ªãnh l√† 1)
            
        Returns:
            str: Property tree ƒë√£ format cho prompt
        """
        try:
            # L·∫•y property tree t·ª´ database (ƒë√£ bao g·ªìm unit types)
            # S·ª≠ d·ª•ng raw SQL ƒë·ªÉ tr√°nh v·∫•n ƒë·ªÅ v·ªõi app context
            import pymysql
            
            # T·∫°o connection ƒë·∫øn warehouse database
            connection = pymysql.connect(
                host=os.getenv('DB_WAREHOUSE_HOST', '103.6.234.59'),
                port=int(os.getenv('DB_WAREHOUSE_PORT', '6033')),
                user=os.getenv('DB_WAREHOUSE_USER', 'root'),
                password=os.getenv('DB_WAREHOUSE_PASSWORD', ''),
                database=os.getenv('DB_WAREHOUSE_NAME', 'warehouse'),
                charset='utf8mb4'
            )
            
            property_tree = PropertyService.get_property_tree_for_prompt_with_sql(root_id, connection)
            connection.close()


            return property_tree
            
        except Exception as e:
            logger.error(f"L·ªói khi l·∫•y property tree: {str(e)}")
            # Fallback v·ªÅ hardcoded data n·∫øu c√≥ l·ªói
            return """Kh√¥ng c√≥ th√¥ng tin d·ª± √°n"""
    
    def process_message_with_groq(self, message_content: str) -> Optional[str]:
        """
        G·ª≠i tin nh·∫Øn t·ªõi Groq API ƒë·ªÉ b√≥c t√°ch th√¥ng tin cƒÉn h·ªô
        
        Args:
            message_content: N·ªôi dung tin nh·∫Øn c·∫ßn x·ª≠ l√Ω
            
        Returns:
            K·∫øt qu·∫£ t·ª´ Groq API ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # L·∫•y property tree t·ª´ database
            property_tree = self.get_property_tree_for_prompt()
            
            # Prompt ƒë·ªÉ Groq tr·∫£ v·ªÅ JSON
            prompt = f"""
            H√£y ph√¢n t√≠ch tin nh·∫Øn rao b√°n cƒÉn h·ªô trong c·∫∑p th·∫ª XML <message></message> v√† tr·∫£ v·ªÅ  duy nh·∫•t JSON string ch·ª©a th√¥ng tin cƒÉn h·ªô nh∆∞ ƒë∆∞·ª£c m√¥ t·∫£ trong c·∫∑p th·∫ª XML <output></output>
            
            <message>
            {message_content}
            </message>
            
            

            <output>
{{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Th√¥ng tin cƒÉn h·ªô rao b√°n",
  "type": "object",
  "properties": {{
    "property_group": {{
      "type": "numer",
      "description": "Ng∆∞·ªùi d√πng ƒëang c√≥ cƒÉn h·ªô rao b√°n t·∫°i t√≤a c√≥ ID l√† bao nhi√™u?"
    }},
    "unit_code": {{
      "type": ["string", "null"],
      "description": "M√£ cƒÉn h·ªô n·∫øu c√≥"
    }},
    "unit_axis": {{
      "type": ["string", "null"],
      "description": "Tr·ª•c cƒÉn n·∫øu c√≥"
    }},
    "unit_floor_number": {{
      "type": ["integer", "null"],
      "description": "T·∫ßng n·∫øu c√≥"
    }},
    "area_land": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch ƒë·∫•t n·∫øu c√≥"
    }},
    "area_construction": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch x√¢y d·ª±ng n·∫øu c√≥"
    }},
    "area_net": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch th√¥ng th·ªßy n·∫øu c√≥"
    }},
    "area_gross": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch tim t∆∞·ªùng n·∫øu c√≥"
    }},
    "num_bedrooms": {{
      "type": ["integer", "null"],
      "description": "S·ªë ph√≤ng ng·ªß n·∫øu c√≥"
    }},
    "num_bathrooms": {{
      "type": ["integer", "null"],
      "description": "S·ªë ph√≤ng t·∫Øm n·∫øu c√≥"
    }},
    "unit_type": {{
      "type": "number",
      "description": "ID c·ªßa lo·∫°i cƒÉn h·ªô"
    }},
    "direction_door": {{
      "type": ["string", "null"],
      "enum": ["D", "T", "N", "B", "DB", "DN", "TB", "TN", null],
      "description": "H∆∞·ªõng c·ª≠a ch√≠nh"
    }},
    "direction_balcony": {{
      "type": ["string", "null"],
      "enum": ["D", "T", "N", "B", "DB", "DN", "TB", "TN", null],
      "description": "H∆∞·ªõng ban c√¥ng"
    }},
    "price": {{
      "type": "number",
      "description": "Gi√° n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_early": {{
      "type": "number",
      "description": "Gi√° thanh to√°n s·ªõm n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_schedule": {{
      "type": "number",
      "description": "Gi√° thanh to√°n theo ti·∫øn ƒë·ªô n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_loan": {{
      "type": "number",
      "description": "Gi√° vay ng√¢n h√†ng n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_rent": {{
      "type": "number",
      "description": "Gi√° vay ng√¢n h√†ng n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "notes": {{
      "type": ["string", "null"],
      "description": "Ghi ch√∫ n·∫øu c√≥"
    }},
    "status": {{
      "type": ["string", "null"],
      "enum": ["CHUA_BAN", "DA_LOCK", "DA_COC", "DA_BAN", null],
      "description": "Tr·∫°ng th√°i n·∫øu c√≥"
    }}
  }},
  "required": ["property_group"],
  "additionalProperties": false
}}
</output>



            {property_tree}

            L∆∞u √Ω quan tr·ªçng:
            - Ch·ªâ tr·∫£ v·ªÅ duy nh·∫•t JSON, kh√¥ng c√≥ n·ªôi dung n√†o kh√°c.
            - Kh√¥ng di·ªÖn gi·∫£i, ch·ªâ tr·∫£ v·ªÅ JSON.
            - N·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p di·ªán t√≠ch m√† kh√¥ng n√≥i l√† lo·∫°i di·ªán t√≠ch g√¨ th√¨ ƒë√≥ ch√≠nh l√† di·ªán t√≠ch tim t∆∞·ªùng.
            - N·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p h∆∞·ªõng m√† kh√¥ng n√≥i l√† h∆∞·ªõng c·ª≠a ch√≠nh hay h∆∞·ªõng ban c√¥ng th√¨ ƒë√≥ ch√≠nh l√† h∆∞·ªõng c·ª≠a ch√≠nh.
            - N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o, tr·∫£ v·ªÅ null cho tr∆∞·ªùng ƒë√≥.
            
            
            
            """

            print("prompt")
            print(prompt)
            # exit()
            
            completion = self.groq_client.chat.completions.create(
                model="openai/gpt-oss-120b",
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,  # Gi·∫£m temperature ƒë·ªÉ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh h∆°n v·ªõi GPT-OSS
                max_completion_tokens=2048,  # TƒÉng token limit cho GPT-OSS
                top_p=0.9,  # Gi·∫£m top_p ƒë·ªÉ t·∫≠p trung h∆°n
                stream=True,
                stop=None
            )
            
            # Collect streaming response v·ªõi error handling t·ªët h∆°n
            response_content = ""
            try:
                for chunk in completion:
                    if hasattr(chunk, 'choices') and chunk.choices and len(chunk.choices) > 0:
                        if hasattr(chunk.choices[0], 'delta') and chunk.choices[0].delta:
                            if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                                response_content += chunk.choices[0].delta.content
            except Exception as stream_error:
                logger.error(f"Error in streaming response: {stream_error}")
                # Fallback: th·ª≠ l·∫•y response kh√¥ng streaming
                try:
                    completion_no_stream = self.groq_client.chat.completions.create(
                        model="openai/gpt-oss-120b",
                        messages=[
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        temperature=0.1,
                        max_completion_tokens=2048,
                        top_p=0.9,
                        stream=False
                    )
                    response_content = completion_no_stream.choices[0].message.content
                except Exception as fallback_error:
                    logger.error(f"Fallback also failed: {fallback_error}")
                    return None
            
            logger.info(f"GPT-OSS processing completed for message, response length: {len(response_content)}")
            return response_content
            
        except Exception as e:
            logger.error(f"Error processing message with Groq: {e}")
            return None
    
    def parse_groq_response(self, groq_response: str) -> Optional[Dict]:
        """
        Parse JSON response t·ª´ Groq/GPT-OSS
        
        Args:
            groq_response: Response t·ª´ Groq API
            
        Returns:
            Dict ch·ª©a th√¥ng tin cƒÉn h·ªô ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # Clean response ƒë·ªÉ l·∫•y JSON
            response_clean = groq_response.strip()
            
            # Log raw response ƒë·ªÉ debug
            logger.info(f"Raw GPT-OSS response: {response_clean[:300]}...")
            
            # T√¨m JSON trong response (c√≥ th·ªÉ c√≥ text kh√°c)
            start_idx = response_clean.find('{')
            end_idx = response_clean.rfind('}')
            
            if start_idx == -1 or end_idx == -1:
                logger.error("No JSON found in GPT-OSS response")
                logger.error(f"Full response: {response_clean}")
                return None
            
            json_str = response_clean[start_idx:end_idx + 1]
            logger.info(f"Extracted JSON: {json_str}")
            
            apartment_data = json.loads(json_str)
            
            # Validate v√† fix data types cho GPT-OSS
            apartment_data = PropertyService.validate_and_fix_apartment_data(apartment_data)
            
            logger.info(f"Successfully parsed GPT-OSS response: {len(apartment_data)} fields")
            return apartment_data
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            logger.error(f"Raw response: {groq_response[:500]}...")
            
            # Th·ª≠ parse l·∫°i v·ªõi m·ªôt s·ªë fix c∆° b·∫£n cho GPT-OSS
            try:
                # Fix common JSON issues v·ªõi GPT-OSS
                fixed_response = response_clean
                
                # Fix c√°c l·ªói ph·ªï bi·∫øn
                fixes = [
                    ('"property_group": "S401"', '"property_group": 401'),
                    ('"unit_axis', '"unit_axis"'),
                    ('"unit_code', '"unit_code"'),
                    ('"price": "3.2 t·ª∑"', '"price": 3200000000'),
                    ('"area_gross": "85m2"', '"area_gross": 85'),
                    ('"num_bedrooms": "2PN"', '"num_bedrooms": 2'),
                    ('"num_bathrooms": "2WC"', '"num_bathrooms": 2'),
                ]
                
                for old, new in fixes:
                    fixed_response = fixed_response.replace(old, new)
                
                # T√¨m JSON l·∫°i
                start_idx = fixed_response.find('{')
                end_idx = fixed_response.rfind('}')
                
                if start_idx != -1 and end_idx != -1:
                    json_str = fixed_response[start_idx:end_idx + 1]
                    apartment_data = json.loads(json_str)
                    apartment_data = PropertyService.validate_and_fix_apartment_data(apartment_data)
                    logger.info("Successfully parsed after fixing JSON")
                    return apartment_data
                    
            except Exception as fix_error:
                logger.error(f"Failed to fix JSON: {fix_error}")
            
            return None
        except Exception as e:
            logger.error(f"Error parsing GPT-OSS response: {e}")
            return None
    
    def map_unit_type_to_id(self, unit_type_name) -> Optional[int]:
        """
        Map unit type name sang ID
        
        Args:
            unit_type_name: T√™n lo·∫°i cƒÉn h·ªô (c√≥ th·ªÉ l√† string ho·∫∑c int)
            
        Returns:
            ID t∆∞∆°ng ·ª©ng ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        if not unit_type_name:
            return None
        
        # N·∫øu ƒë√£ l√† int th√¨ return lu√¥n
        if isinstance(unit_type_name, int):
            return unit_type_name
            
        # Convert to string n·∫øu c·∫ßn
        unit_type_str = str(unit_type_name)
            
        # T√¨m exact match tr∆∞·ªõc
        if unit_type_str in self.unit_type_mapping:
            return self.unit_type_mapping[unit_type_str]
        
        # T√¨m partial match
        for name, id_val in self.unit_type_mapping.items():
            if unit_type_str.lower() in name.lower() or name.lower() in unit_type_str.lower():
                logger.info(f"Mapped '{unit_type_name}' to '{name}' (ID: {id_val})")
                return id_val
        
        logger.warning(f"Unit type '{unit_type_name}' not found in mapping")
        return None
    
    def insert_apartment_via_api(self, apartment_data: Dict) -> tuple[bool, int | None]:
        """
        Insert apartment v√†o warehouse database th√¥ng qua API
        
        Args:
            apartment_data: D·ªØ li·ªáu cƒÉn h·ªô t·ª´ Groq
            
        Returns:
            Tuple (success: bool, apartment_id: int | None)
        """
        try:
            import requests
            
            # Map unit_type name sang ID
            unit_type_id = None
            if apartment_data.get('unit_type'):
                unit_type_id = self.map_unit_type_to_id(apartment_data['unit_type'])
            
            # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ g·ª≠i t·ªõi API
            logger.info(f"üîç Original apartment_data: {apartment_data}")
            logger.info(f"üîç unit_type_id mapped: {unit_type_id}")
            
            apartment_record = {
                'property_group': apartment_data.get('property_group', 1),  # Default to 1
                'unit_type': unit_type_id,
                'unit_code': apartment_data.get('unit_code'),
                'unit_axis': apartment_data.get('unit_axis'),
                'unit_floor_number': apartment_data.get('unit_floor_number'),
                'area_land': apartment_data.get('area_land'),
                'area_construction': apartment_data.get('area_construction'),
                'area_net': apartment_data.get('area_net'),
                'area_gross': apartment_data.get('area_gross'),
                'num_bedrooms': apartment_data.get('num_bedrooms'),
                'num_bathrooms': apartment_data.get('num_bathrooms'),
                'type_view': apartment_data.get('type_view'),
                'direction_door': apartment_data.get('direction_door'),
                'direction_balcony': apartment_data.get('direction_balcony'),
                'price': apartment_data.get('price'),
                'price_early': apartment_data.get('price_early'),
                'price_schedule': apartment_data.get('price_schedule'),
                'price_loan': apartment_data.get('price_loan'),
                'notes': apartment_data.get('notes'),
                'status': apartment_data.get('status'),
                'unit_allocation': 'QUY_CHEO'  # Lu√¥n set m·∫∑c ƒë·ªãnh
            }
            
            logger.info(f"üîç Prepared apartment_record: {apartment_record}")
            
            # G·ªçi API warehouse ƒë·ªÉ insert
            api_url = f"http://localhost:5000/warehouse/api/warehouse/apartments/single-insert"
            
            response = requests.post(api_url, json=apartment_record, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    apartment_id = result.get('data', {}).get('apartment_id')
                    logger.info(f"‚úÖ Successfully inserted apartment via API: {apartment_record.get('unit_code', 'N/A')} (ID: {apartment_id})")
                    return True, apartment_id
                else:
                    logger.error(f"‚ùå API returned error: {result.get('error')}")
                    return False, None
            else:
                logger.error(f"‚ùå API request failed with status {response.status_code}: {response.text}")
                return False, None
                
        except Exception as e:
            logger.error(f"‚ùå Error calling warehouse API: {str(e)}")
            logger.error(f"‚ùå Error type: {type(e)}")
            logger.error(f"‚ùå Error details: {e}")
            import traceback
            logger.error(f"‚ùå Full traceback: {traceback.format_exc()}")
            return False, None
                    'unit_floor_number': apartment_data.get('unit_floor_number'),
                    'area_land': apartment_data.get('area_land'),
                    'area_construction': apartment_data.get('area_construction'),
                    'area_net': apartment_data.get('area_net'),
                    'area_gross': apartment_data.get('area_gross'),
                    'num_bedrooms': apartment_data.get('num_bedrooms'),
                    'num_bathrooms': apartment_data.get('num_bathrooms'),
                    'type_view': None,  # Hardcode
                    'direction_door': apartment_data.get('direction_door'),
                    'direction_balcony': apartment_data.get('direction_balcony'),
                    'price': apartment_data.get('price'),
                    'price_early': apartment_data.get('price_early'),
                    'price_schedule': apartment_data.get('price_schedule'),
                    'price_loan': apartment_data.get('price_loan'),
                    'notes': apartment_data.get('notes'),
                    'status': apartment_data.get('status'),
                    'unit_allocation': 'QUY_CHEO'  # Hardcode
                }
                
                # Ki·ªÉm tra xem c√≥ cƒÉn h·ªô n√†o v·ªõi unit_code n√†y ch∆∞a
                if apartment_record['unit_code']:
                    check_query = text("SELECT id FROM apartments WHERE unit_code = :unit_code")
                    result = connection.execute(check_query, {"unit_code": apartment_record['unit_code']})
                    existing = result.fetchone()
                    
                    if existing:
                        # Update existing record
                        update_fields = []
                        update_values = {}
                        
                        for field, value in apartment_record.items():
                            if value is not None and field != 'property_group':  # Kh√¥ng update property_group
                                update_fields.append(f"{field} = :{field}")
                                update_values[field] = value
                        
                        if update_fields:
                            update_values['id'] = existing[0]  # Add ID for WHERE clause
                            update_query = text(f"""
                                UPDATE apartments 
                                SET {', '.join(update_fields)}
                                WHERE id = :id
                            """)
                            connection.execute(update_query, update_values)
                            logger.info(f"Updated apartment with unit_code: {apartment_record['unit_code']}")
                    else:
                        # Insert new record
                        insert_fields = []
                        insert_values = {}
                        
                        for field, value in apartment_record.items():
                            if value is not None:
                                insert_fields.append(field)
                                insert_values[field] = value
                        
                        if insert_fields:
                            placeholders = [f":{field}" for field in insert_fields]
                            insert_query = text(f"""
                                INSERT INTO apartments ({', '.join(insert_fields)})
                                VALUES ({', '.join(placeholders)})
                            """)
                            connection.execute(insert_query, insert_values)
                            logger.info(f"Inserted new apartment with unit_code: {apartment_record['unit_code']}")
                else:
                    # Kh√¥ng c√≥ unit_code, insert m·ªõi
                    insert_fields = []
                    insert_values = {}
                    
                    for field, value in apartment_record.items():
                        if value is not None:
                            insert_fields.append(field)
                            insert_values[field] = value
                    
                    if insert_fields:
                        placeholders = [f":{field}" for field in insert_fields]
                        insert_query = text(f"""
                            INSERT INTO apartments ({', '.join(insert_fields)})
                            VALUES ({', '.join(placeholders)})
                        """)
                        connection.execute(insert_query, insert_values)
                        logger.info("Inserted new apartment without unit_code")
                
                connection.commit()
                return True
                
        except Exception as e:
            logger.error(f"Error inserting/updating apartment: {e}")
            return False
        finally:
            if connection:
                connection.close()
    
    def update_message_status(self, message_id: int, status: str = 'PUSHED') -> bool:
        """
        C·∫≠p nh·∫≠t tr·∫°ng th√°i tin nh·∫Øn sau khi x·ª≠ l√Ω v·ªõi retry mechanism
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn
            status: Tr·∫°ng th√°i m·ªõi ('PUSHED' ho·∫∑c 'NOT_YET')
            
        Returns:
            True n·∫øu c·∫≠p nh·∫≠t th√†nh c√¥ng, False n·∫øu l·ªói
        """
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            connection = None
            try:
                logger.info(f"Updating message {message_id} status to {status} (attempt {attempt + 1}/{max_retries})")
                
                with zalo_app.app_context():
                    connection = self.get_zalo_db_connection()
                    if not connection:
                        logger.error(f"No database connection available (attempt {attempt + 1})")
                        continue
                    
                    from sqlalchemy import text
                    query = text("""
                    UPDATE received_messages 
                    SET status_push_warehouse = :status 
                    WHERE id = :message_id
                    """)
                    
                    connection.execute(query, {"status": status, "message_id": message_id})
                    connection.commit()
                    
                    logger.info(f"‚úÖ Updated message {message_id} status to {status}")
                    return True
                    
            except Exception as e:
                logger.error(f"‚ùå Error updating message status (attempt {attempt + 1}): {e}")
                logger.error(f"Error type: {type(e)}")
                
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    logger.error("‚ùå Failed to update message status after all retries")
                    return False
                    
            finally:
                if connection:
                    try:
                        connection.close()
                    except Exception as close_error:
                        logger.warning(f"Warning: Error closing connection: {close_error}")
        
        return False
    
    def process_messages_batch(self, limit: int = 20):
        """X·ª≠ l√Ω m·ªôt batch tin nh·∫Øn"""
        logger.info(f"Starting message batch processing (limit: {limit})...")
        
        # L·∫•y tin nh·∫Øn ch∆∞a x·ª≠ l√Ω
        messages = self.get_unprocessed_messages(limit=limit)
        
        if not messages:
            logger.info("No unprocessed messages found")
            return 0, 0
        
        processed_count = 0
        error_count = 0
        
        for message in messages:
            try:
                message_id = message['id']
                content = message['content']
                
                logger.info(f"Processing message {message_id}")
                
                # G·ª≠i t·ªõi Groq ƒë·ªÉ b√≥c t√°ch th√¥ng tin
                groq_result = self.process_message_with_groq(content)
                
                if groq_result:
                    logger.info(f"Groq result for message {message_id}: {groq_result[:100]}...")
                    
                    # Parse JSON t·ª´ Groq response
                    apartment_data = self.parse_groq_response(groq_result)
                    
                    if apartment_data:
                        # Insert/update v√†o warehouse database
                        warehouse_success = self.insert_apartment_via_api(apartment_data)
                        
                        if warehouse_success:
                            # Ch·ªâ c·∫≠p nh·∫≠t tr·∫°ng th√°i tin nh·∫Øn sau khi x·ª≠ l√Ω warehouse th√†nh c√¥ng
                            if self.update_message_status(message_id, 'PUSHED'):
                                processed_count += 1
                                logger.info(f"Successfully processed message {message_id}")
                            else:
                                error_count += 1
                                logger.error(f"Failed to update message {message_id} status")
                        else:
                            error_count += 1
                            logger.error(f"Failed to insert/update apartment for message {message_id}")
                    else:
                        error_count += 1
                        logger.error(f"Failed to parse Groq response for message {message_id}")
                else:
                    logger.error(f"Failed to process message {message_id} with Groq")
                    error_count += 1
                    
            except Exception as e:
                logger.error(f"Error processing message {message.get('id', 'unknown')}: {e}")
                error_count += 1
        
        logger.info(f"Batch processing completed. Processed: {processed_count}, Errors: {error_count}")
        return processed_count, error_count
    
    def run_test_mode(self, limit: int = 50):
        """Ch·∫ø ƒë·ªô test - ch·∫°y m·ªôt s·ªë tin nh·∫Øn ƒë·∫ßu ƒë·ªÉ th·ª≠"""
        logger.info(f"üß™ Running in TEST mode - processing {limit} messages")
        
        start_time = time.time()
        processed_count, error_count = self.process_messages_batch(limit=limit)
        elapsed_time = time.time() - start_time
        
        logger.info(f"‚úÖ TEST mode completed in {elapsed_time:.2f}s")
        logger.info(f"üìä Results: {processed_count} processed, {error_count} errors")
        
        return processed_count, error_count
    
    def get_message_by_id(self, message_id: int) -> Optional[Dict]:
        """
        L·∫•y tin nh·∫Øn theo ID
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn c·∫ßn l·∫•y
            
        Returns:
            Dict ch·ª©a th√¥ng tin tin nh·∫Øn ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        try:
            logger.info(f"üîç Fetching message with ID: {message_id}")
            
            with zalo_app.app_context():
                connection = self.get_zalo_db_connection()
                if not connection:
                    logger.error("‚ùå No database connection available")
                    return None
                
                from sqlalchemy import text
                
                query = text("""
                SELECT id, session_id, config_id, sender_id, sender_name, 
                       content, thread_id, thread_type, received_at, 
                       status_push_kafka, status_push_warehouse, reply_quote
                FROM received_messages 
                WHERE id = :message_id
                """)
                
                result = connection.execute(query, {"message_id": message_id})
                row = result.fetchone()
                
                if row:
                    message_data = dict(row._mapping)
                    logger.info(f"‚úÖ Found message {message_id}: {message_data.get('content', '')[:100]}...")
                    return message_data
                else:
                    logger.warning(f"‚ùå Message with ID {message_id} not found")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Error fetching message {message_id}: {e}")
            return None
        finally:
            if connection:
                connection.close()
    
    def run_test_one_mode(self, message_id: int):
        """
        Ch·∫ø ƒë·ªô test one - test m·ªôt tin nh·∫Øn c·ª• th·ªÉ theo ID
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn c·∫ßn test
        """
        logger.info(f"üß™ Running in TEST-ONE mode - processing message ID: {message_id}")
        
        start_time = time.time()
        
        try:
            # L·∫•y tin nh·∫Øn theo ID
            message = self.get_message_by_id(message_id)
            
            if not message:
                logger.error(f"‚ùå Message with ID {message_id} not found")
                return None, "Message not found"
            
            content = message['content']
            logger.info(f"üìù Message content: {content}")
            
            # G·ª≠i t·ªõi Groq ƒë·ªÉ b√≥c t√°ch th√¥ng tin
            logger.info("ü§ñ Processing with Groq...")
            groq_result = self.process_message_with_groq(content)
            
            
            if groq_result:
                logger.info(f"‚úÖ Groq result: {groq_result}")
                
                # Parse JSON t·ª´ Groq response
                apartment_data = self.parse_groq_response(groq_result)
                
                if apartment_data:
                    logger.info(f"üìä Parsed apartment data: {apartment_data}")
                    
                    # Test insert/update v√†o warehouse database (kh√¥ng commit th·∫≠t)
                    logger.info("üè† Testing warehouse insert/update...")
                    warehouse_success = self.insert_apartment_via_api(apartment_data)
                    
                    if warehouse_success:
                        logger.info("‚úÖ Warehouse insert/update successful")
                        result = {
                            'message_id': message_id,
                            'message_content': content,
                            'groq_result': groq_result,
                            'parsed_data': apartment_data,
                            'warehouse_success': True
                        }
                    else:
                        logger.error("‚ùå Warehouse insert/update failed")
                        result = {
                            'message_id': message_id,
                            'message_content': content,
                            'groq_result': groq_result,
                            'parsed_data': apartment_data,
                            'warehouse_success': False,
                            'error': 'Warehouse insert/update failed'
                        }
                else:
                    logger.error("‚ùå Failed to parse Groq response")
                    result = {
                        'message_id': message_id,
                        'message_content': content,
                        'groq_result': groq_result,
                        'parsed_data': None,
                        'warehouse_success': False,
                        'error': 'Failed to parse Groq response'
                    }
            else:
                logger.error("‚ùå Failed to process message with Groq")
                result = {
                    'message_id': message_id,
                    'message_content': content,
                    'groq_result': None,
                    'parsed_data': None,
                    'warehouse_success': False,
                    'error': 'Failed to process with Groq'
                }
            
            elapsed_time = time.time() - start_time
            logger.info(f"‚úÖ TEST-ONE mode completed in {elapsed_time:.2f}s")
            
            return result, None
            
        except Exception as e:
            logger.error(f"‚ùå Error in test-one mode: {e}")
            return None, str(e)
    
    def run_batch_mode(self):
        """Ch·∫ø ƒë·ªô batch - ch·∫°y t·∫•t c·∫£ tin nh·∫Øn t·ª´ tr∆∞·ªõc ƒë·∫øn nay"""
        logger.info("üì¶ Running in BATCH mode - processing ALL unprocessed messages")
        
        total_processed = 0
        total_errors = 0
        batch_size = 100  # X·ª≠ l√Ω t·ª´ng batch 100 tin nh·∫Øn
        batch_count = 0
        
        start_time = time.time()
        
        while True:
            batch_count += 1
            logger.info(f"Processing batch {batch_count} (size: {batch_size})")
            
            processed_count, error_count = self.process_messages_batch(limit=batch_size)
            
            total_processed += processed_count
            total_errors += error_count
            
            # N·∫øu kh√¥ng c√≥ tin nh·∫Øn n√†o ƒë∆∞·ª£c x·ª≠ l√Ω, d·ª´ng l·∫°i
            if processed_count == 0:
                break
                
            logger.info(f"Batch {batch_count} completed: {processed_count} processed, {error_count} errors")
        
        elapsed_time = time.time() - start_time
        
        logger.info(f"‚úÖ BATCH mode completed in {elapsed_time:.2f}s")
        logger.info(f"üìä Total results: {total_processed} processed, {total_errors} errors across {batch_count} batches")
        
        return total_processed, total_errors
    
    def run_scheduler_mode(self):
        """Ch·∫ø ƒë·ªô scheduler - ch·∫°y ƒë·ªãnh k·ª≥ nh∆∞ hi·ªán t·∫°i"""
        logger.info(f"‚è∞ Running in SCHEDULER mode (interval: {self.interval//60} minutes)")
        
        while self.is_running:
            try:
                start_time = time.time()
                
                # X·ª≠ l√Ω batch tin nh·∫Øn
                self.process_messages_batch(limit=20)
                
                # T√≠nh th·ªùi gian c√≤n l·∫°i ƒë·ªÉ sleep
                elapsed_time = time.time() - start_time
                sleep_time = max(0, self.interval - elapsed_time)
                
                logger.info(f"Processing completed in {elapsed_time:.2f}s. Sleeping for {sleep_time/60:.1f} minutes")
                
                # Sleep v·ªõi ki·ªÉm tra is_running ƒë·ªÉ c√≥ th·ªÉ d·ª´ng nhanh
                for _ in range(int(sleep_time)):
                    if not self.is_running:
                        break
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"Error in scheduler: {e}")
                # Sleep 60 gi√¢y n·∫øu c√≥ l·ªói ƒë·ªÉ tr√°nh spam
                time.sleep(60)
    
    def run_scheduler(self):
        """Ch·∫°y scheduler ƒë·ªãnh k·ª≥ (legacy method)"""
        self.run_scheduler_mode()
    
    def start(self):
        """B·∫Øt ƒë·∫ßu service"""
        if self.is_running:
            logger.warning("Service is already running")
            return
        
        # Ki·ªÉm tra xem schedule c√≥ ƒë∆∞·ª£c enable kh√¥ng
        if not self.schedule_enabled:
            logger.info("ZaloMessageProcessor schedule is disabled (ZALO_MESSAGE_PROCESSOR_SCHEDULE=0)")
            return
        
        self.is_running = True
        self.thread = threading.Thread(target=self.run_scheduler, daemon=True)
        self.thread.start()
        
        logger.info(f"ZaloMessageProcessor service started (interval: {self.interval//60} minutes)")
    
    def stop(self):
        """D·ª´ng service"""
        if not self.is_running:
            logger.warning("Service is not running")
            return
        
        self.is_running = False
        
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=5)
        
        logger.info("ZaloMessageProcessor service stopped")
    
    def get_status(self) -> Dict:
        """L·∫•y tr·∫°ng th√°i service"""
        return {
            'is_running': self.is_running,
            'thread_alive': self.thread.is_alive() if self.thread else False,
            'interval': self.interval,
            'interval_minutes': self.interval // 60,
            'schedule_enabled': self.schedule_enabled,
            'started_at': datetime.now().isoformat() if self.is_running else None
        }


# Global instance
zalo_processor = ZaloMessageProcessor()

def main():
    """Main function v·ªõi command line arguments"""
    parser = argparse.ArgumentParser(description='Zalo Message Processor Service')
    parser.add_argument('--mode', choices=['test', 'test-one', 'batch', 'scheduler'], default='scheduler',
                       help='Ch·∫ø ƒë·ªô ch·∫°y: test (50 tin nh·∫Øn), test-one (1 tin nh·∫Øn theo ID), batch (t·∫•t c·∫£), scheduler (ƒë·ªãnh k·ª≥)')
    parser.add_argument('--limit', type=int, default=50,
                       help='S·ªë l∆∞·ª£ng tin nh·∫Øn cho ch·∫ø ƒë·ªô test (default: 50)')
    parser.add_argument('--message-id', type=int,
                       help='ID c·ªßa tin nh·∫Øn c·∫ßn test (ch·ªâ d√πng v·ªõi mode test-one)')
    
    args = parser.parse_args()
    
    try:
        if args.mode == 'test':
            logger.info(f"üß™ Starting ZaloMessageProcessor in TEST mode (limit: {args.limit})")
            zalo_processor.run_test_mode(limit=args.limit)
            
        elif args.mode == 'test-one':
            if not args.message_id:
                logger.error("‚ùå --message-id is required for test-one mode")
                return
            logger.info(f"üß™ Starting ZaloMessageProcessor in TEST-ONE mode (message ID: {args.message_id})")
            result, error = zalo_processor.run_test_one_mode(args.message_id)
            
            if error:
                logger.error(f"‚ùå Test failed: {error}")
            else:
                logger.info("‚úÖ Test completed successfully")
                logger.info(f"üìä Result: {result}")
            
        elif args.mode == 'batch':
            logger.info("üì¶ Starting ZaloMessageProcessor in BATCH mode")
            zalo_processor.run_batch_mode()
            
        elif args.mode == 'scheduler':
            logger.info("‚è∞ Starting ZaloMessageProcessor in SCHEDULER mode")
            zalo_processor.start()
            
            # Gi·ªØ service ch·∫°y
            while zalo_processor.is_running:
                time.sleep(1)
                
    except KeyboardInterrupt:
        logger.info("Received interrupt signal, stopping service...")
        if args.mode == 'scheduler':
            zalo_processor.stop()
    except Exception as e:
        logger.error(f"Service error: {e}")
        if args.mode == 'scheduler':
            zalo_processor.stop()

if __name__ == "__main__":
    main()
