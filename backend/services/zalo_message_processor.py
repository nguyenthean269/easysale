"""
Zalo Message Processor Service
Service x·ª≠ l√Ω tin nh·∫Øn t·ª´ Zalo ƒë·ªãnh k·ª≥ 10 ph√∫t m·ªôt l·∫ßn
"""

import os
import time
import threading
import logging
import json
import argparse
from datetime import datetime
from typing import List, Dict, Optional
from groq import Groq
from dotenv import load_dotenv
from flask import Flask
from flask_sqlalchemy import SQLAlchemy
from utils.property_service_sql import PropertyService
from .warehouse_database_service import warehouse_service

# Load environment variables
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), '..', '.env'))

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Debug environment variables
logger.info("üîß Environment variables loaded:")
logger.info(f"DB_CHAT_HOST: {os.getenv('DB_CHAT_HOST', 'NOT_SET')}")
logger.info(f"DB_CHAT_PORT: {os.getenv('DB_CHAT_PORT', 'NOT_SET')}")
logger.info(f"DB_CHAT_USER: {os.getenv('DB_CHAT_USER', 'NOT_SET')}")
logger.info(f"DB_CHAT_PASSWORD: {'SET' if os.getenv('DB_CHAT_PASSWORD') else 'NOT_SET'}")
logger.info(f"DB_NAME: {os.getenv('DB_NAME', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_HOST: {os.getenv('DB_WAREHOUSE_HOST', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_PORT: {os.getenv('DB_WAREHOUSE_PORT', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_USER: {os.getenv('DB_WAREHOUSE_USER', 'NOT_SET')}")
logger.info(f"DB_WAREHOUSE_PASSWORD: {'SET' if os.getenv('DB_WAREHOUSE_PASSWORD') else 'NOT_SET'}")
logger.info(f"DB_WAREHOUSE_NAME: {os.getenv('DB_WAREHOUSE_NAME', 'NOT_SET')}")

# T·∫°o Flask app cho easychat database
zalo_app = Flask(__name__)
zalo_app.config['SQLALCHEMY_DATABASE_URI'] = f"mysql://{os.getenv('DB_CHAT_USER', 'easychat')}:{os.getenv('DB_CHAT_PASSWORD', '')}@{os.getenv('DB_CHAT_HOST', '103.6.234.59')}:{os.getenv('DB_CHAT_PORT', '6033')}/{os.getenv('DB_NAME', 'easychat')}"
zalo_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
zalo_db = SQLAlchemy(zalo_app)

# Warehouse database service ƒë∆∞·ª£c import t·ª´ warehouse_database_service.py

class ZaloMessageProcessor:
    """Service x·ª≠ l√Ω tin nh·∫Øn Zalo ƒë·ªãnh k·ª≥"""
    
    def __init__(self):
        """Kh·ªüi t·∫°o service"""
        # Groq client
        self.groq_client = Groq(api_key=os.getenv('GROQ_API_KEY'))
        
        # Service control
        self.is_running = False
        self.thread = None
        
        # L·∫•y interval t·ª´ environment variable (ƒë∆°n v·ªã ph√∫t)
        schedule_minutes = int(os.getenv('ZALO_MESSAGE_PROCESSOR_SCHEDULE', '10'))
        self.interval = schedule_minutes * 60  # Chuy·ªÉn t·ª´ ph√∫t sang gi√¢y
        self.schedule_enabled = schedule_minutes > 0  # Ch·ªâ enable n·∫øu > 0
        
        # Warehouse service instance
        self.warehouse_service = warehouse_service
        
        logger.info(f"ZaloMessageProcessor initialized (schedule: {self.interval//60} minutes, enabled: {self.schedule_enabled})")
    
    def get_zalo_db_connection(self):
        """T·∫°o k·∫øt n·ªëi database easychat v·ªõi retry mechanism"""
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            try:
                logger.info(f"Attempting to connect to easychat database... (attempt {attempt + 1}/{max_retries})")
                
                with zalo_app.app_context():
                    # S·ª≠ d·ª•ng SQLAlchemy engine v·ªõi connection pooling
                    connection = zalo_db.engine.connect()
                    logger.info("‚úÖ Easychat database connection successful")
                    return connection
                    
            except Exception as e:
                logger.error(f"‚ùå Easychat database connection error (attempt {attempt + 1}): {e}")
                logger.error(f"Error type: {type(e)}")
                
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    logger.error("‚ùå Failed to connect to easychat database after all retries")
        
        return None
    
    def get_warehouse_db_connection(self):
        """T·∫°o k·∫øt n·ªëi database warehouse v·ªõi retry mechanism"""
        return self.warehouse_service.get_warehouse_db_connection()
    
    def get_unprocessed_messages(self, limit: int = 20, warehouse_id: str = 'NULL') -> List[Dict]:
        """
        L·∫•y danh s√°ch tin nh·∫Øn t·ª´ b·∫£ng zalo_received_messages trong database easychat theo warehouse_id
        
        Args:
            limit: S·ªë l∆∞·ª£ng tin nh·∫Øn t·ªëi ƒëa c·∫ßn l·∫•y
            warehouse_id: Tr·∫°ng th√°i warehouse_id ('NULL', 'NOT_NULL', 'ALL')
            
        Returns:
            List c√°c tin nh·∫Øn theo warehouse_id
        """
        try:
            logger.info("üîç Starting to fetch unprocessed messages...")
            
            # Retry logic cho connection
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    logger.info(f"üîÑ Attempt {attempt + 1}/{max_retries}")
                    
                    with zalo_app.app_context():
                        logger.info("üì° Zalo app context created")
                        connection = self.get_zalo_db_connection()
                        if not connection:
                            logger.error("‚ùå No database connection available")
                            continue
                        
                        logger.info("üìä Executing query to fetch messages...")
                        from sqlalchemy import text
                        
                        # X√¢y d·ª±ng WHERE clause d·ª±a tr√™n warehouse_id
                        if warehouse_id == 'ALL':
                            where_clause = ""
                            params = {"limit": limit}
                        elif warehouse_id == 'NULL':
                            where_clause = "WHERE warehouse_id IS NULL"
                            params = {"limit": limit}
                        elif warehouse_id == 'NOT_NULL':
                            where_clause = "WHERE warehouse_id IS NOT NULL"
                            params = {"limit": limit}
                        else:
                            # N·∫øu warehouse_id l√† m·ªôt s·ªë c·ª• th·ªÉ
                            where_clause = "WHERE warehouse_id = :warehouse_id"
                            params = {"limit": limit, "warehouse_id": warehouse_id}
                        
                        query = text(f"""
                        SELECT id, session_id, config_id, sender_id, sender_name, 
                               content, thread_id, thread_type, received_at, 
                               status_push_kafka, warehouse_id, reply_quote,
                               content_hash, added_document_chunks
                        FROM zalo_received_messages 
                        {where_clause}
                        ORDER BY received_at ASC 
                        LIMIT :limit
                        """)
                        
                        logger.info(f"üîç Query: {query}")
                        logger.info(f"üîç Limit: {limit}")
                        logger.info(f"üîç Warehouse ID filter: {warehouse_id}")
                        
                        result = connection.execute(query, params)
                        logger.info("‚úÖ Query executed successfully")
                        
                        messages = []
                        for row in result:
                            messages.append(dict(row._mapping))
                        
                        logger.info(f"‚úÖ Found {len(messages)} unprocessed messages")
                        return messages
                        
                except Exception as e:
                    logger.error(f"‚ùå Attempt {attempt + 1} failed: {e}")
                    if attempt < max_retries - 1:
                        logger.info(f"üîÑ Retrying in 2 seconds...")
                        time.sleep(2)
                    else:
                        raise e
                        
        except Exception as e:
            logger.error(f"‚ùå Error fetching messages after {max_retries} attempts: {e}")
            logger.error(f"‚ùå Error type: {type(e)}")
            import traceback
            logger.error(f"‚ùå Traceback: {traceback.format_exc()}")
            return []
    
    def get_property_tree_for_prompt(self, root_id: int = 1) -> str:
        """
        L·∫•y property tree cho prompt
        
        Args:
            root_id (int): ID c·ªßa root group (m·∫∑c ƒë·ªãnh l√† 1)
            
        Returns:
            str: Property tree ƒë√£ format cho prompt
        """
        return self.warehouse_service.get_property_tree_for_prompt(root_id)
    
    def process_message_with_groq(self, message_content: str) -> Optional[str]:
        """
        G·ª≠i tin nh·∫Øn t·ªõi Groq API ƒë·ªÉ b√≥c t√°ch th√¥ng tin cƒÉn h·ªô
        
        Args:
            message_content: N·ªôi dung tin nh·∫Øn c·∫ßn x·ª≠ l√Ω
            
        Returns:
            K·∫øt qu·∫£ t·ª´ Groq API ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # L·∫•y property tree t·ª´ database
            property_tree = self.get_property_tree_for_prompt()
            
            # Prompt ƒë·ªÉ Groq tr·∫£ v·ªÅ JSON
            prompt = f"""
            H√£y ph√¢n t√≠ch tin nh·∫Øn rao b√°n cƒÉn h·ªô trong c·∫∑p th·∫ª XML <message></message> v√† tr·∫£ v·ªÅ  duy nh·∫•t JSON string ch·ª©a th√¥ng tin cƒÉn h·ªô nh∆∞ ƒë∆∞·ª£c m√¥ t·∫£ trong c·∫∑p th·∫ª XML <output></output>
            
            <message>
            {message_content}
            </message>
            
            

            <output>
{{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Th√¥ng tin cƒÉn h·ªô rao b√°n",
  "type": "object",
  "properties": {{
    "property_group": {{
      "type": "numer",
      "description": "Ng∆∞·ªùi d√πng ƒëang c√≥ cƒÉn h·ªô rao b√°n t·∫°i t√≤a c√≥ ID l√† bao nhi√™u?"
    }},
    "unit_code": {{
      "type": ["string", "null"],
      "description": "M√£ cƒÉn h·ªô n·∫øu c√≥"
    }},
    "unit_axis": {{
      "type": ["string", "null"],
      "description": "Tr·ª•c cƒÉn n·∫øu c√≥"
    }},
    "unit_floor_number": {{
      "type": ["integer", "null"],
      "description": "T·∫ßng n·∫øu c√≥"
    }},
    "area_land": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch ƒë·∫•t n·∫øu c√≥"
    }},
    "area_construction": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch x√¢y d·ª±ng n·∫øu c√≥"
    }},
    "area_net": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch th√¥ng th·ªßy n·∫øu c√≥"
    }},
    "area_gross": {{
      "type": ["number", "null"],
      "description": "Di·ªán t√≠ch tim t∆∞·ªùng n·∫øu c√≥"
    }},
    "num_bedrooms": {{
      "type": ["integer", "null"],
      "description": "S·ªë ph√≤ng ng·ªß n·∫øu c√≥"
    }},
    "num_bathrooms": {{
      "type": ["integer", "null"],
      "description": "S·ªë ph√≤ng t·∫Øm n·∫øu c√≥"
    }},
    "unit_type": {{
      "type": "number",
      "description": "ID c·ªßa lo·∫°i cƒÉn h·ªô"
    }},
    "direction_door": {{
      "type": ["string", "null"],
      "enum": ["D", "T", "N", "B", "DB", "DN", "TB", "TN", null],
      "description": "H∆∞·ªõng c·ª≠a ch√≠nh"
    }},
    "direction_balcony": {{
      "type": ["string", "null"],
      "enum": ["D", "T", "N", "B", "DB", "DN", "TB", "TN", null],
      "description": "H∆∞·ªõng ban c√¥ng"
    }},
    "price": {{
      "type": "number",
      "description": "Gi√° n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_early": {{
      "type": "number",
      "description": "Gi√° thanh to√°n s·ªõm n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_schedule": {{
      "type": "number",
      "description": "Gi√° thanh to√°n theo ti·∫øn ƒë·ªô n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_loan": {{
      "type": "number",
      "description": "Gi√° vay ng√¢n h√†ng n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "price_rent": {{
      "type": "number",
      "description": "Gi√° vay ng√¢n h√†ng n·∫øu c√≥. ƒê∆°n v·ªã VNƒê"
    }},
    "notes": {{
      "type": ["string", "null"],
      "description": "Ghi ch√∫ n·∫øu c√≥"
    }},
    "status": {{
      "type": ["string", "null"],
      "enum": ["CHUA_BAN", "DA_LOCK", "DA_COC", "DA_BAN", null],
      "description": "Tr·∫°ng th√°i n·∫øu c√≥"
    }}
  }},
  "required": ["property_group"],
  "additionalProperties": false
}}
</output>



            {property_tree}

            L∆∞u √Ω quan tr·ªçng:
            - Ch·ªâ tr·∫£ v·ªÅ duy nh·∫•t JSON, kh√¥ng c√≥ n·ªôi dung n√†o kh√°c.
            - Kh√¥ng di·ªÖn gi·∫£i, ch·ªâ tr·∫£ v·ªÅ JSON.
            - N·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p di·ªán t√≠ch m√† kh√¥ng n√≥i l√† lo·∫°i di·ªán t√≠ch g√¨ th√¨ ƒë√≥ ch√≠nh l√† di·ªán t√≠ch tim t∆∞·ªùng.
            - N·∫øu ng∆∞·ªùi d√πng ƒë·ªÅ c·∫≠p h∆∞·ªõng m√† kh√¥ng n√≥i l√† h∆∞·ªõng c·ª≠a ch√≠nh hay h∆∞·ªõng ban c√¥ng th√¨ ƒë√≥ ch√≠nh l√† h∆∞·ªõng c·ª≠a ch√≠nh.
            - N·∫øu b√†i ƒëƒÉng c√≥ gi√° ti·ªÅn tri·ªáu th√¨ ƒë√≥ l√† gi√° thu√™, gi√° ti·ªÅn t·ª∑ th√¨ ƒë√≥ l√† gi√° b√°n.
            - N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin n√†o, tr·∫£ v·ªÅ null cho tr∆∞·ªùng ƒë√≥.
            
            
            
            """

            print("prompt")
            print(prompt)
            # exit()
            
            completion = self.groq_client.chat.completions.create(
                model="openai/gpt-oss-120b",
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,  # Gi·∫£m temperature ƒë·ªÉ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh h∆°n v·ªõi GPT-OSS
                max_completion_tokens=2048,  # TƒÉng token limit cho GPT-OSS
                top_p=0.9,  # Gi·∫£m top_p ƒë·ªÉ t·∫≠p trung h∆°n
                stream=True,
                stop=None
            )
            
            # Collect streaming response v·ªõi error handling t·ªët h∆°n
            response_content = ""
            try:
                for chunk in completion:
                    if hasattr(chunk, 'choices') and chunk.choices and len(chunk.choices) > 0:
                        if hasattr(chunk.choices[0], 'delta') and chunk.choices[0].delta:
                            if hasattr(chunk.choices[0].delta, 'content') and chunk.choices[0].delta.content:
                                response_content += chunk.choices[0].delta.content
            except Exception as stream_error:
                logger.error(f"Error in streaming response: {stream_error}")
                # Fallback: th·ª≠ l·∫•y response kh√¥ng streaming
                try:
                    completion_no_stream = self.groq_client.chat.completions.create(
                        model="openai/gpt-oss-120b",
                        messages=[
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        temperature=0.1,
                        max_completion_tokens=2048,
                        top_p=0.9,
                        stream=False
                    )
                    response_content = completion_no_stream.choices[0].message.content
                except Exception as fallback_error:
                    logger.error(f"Fallback also failed: {fallback_error}")
                    return None
            
            logger.info(f"GPT-OSS processing completed for message, response length: {len(response_content)}")
            return response_content
            
        except Exception as e:
            logger.error(f"Error processing message with Groq: {e}")
            return None
    
    def parse_groq_response(self, groq_response: str) -> Optional[Dict]:
        """
        Parse JSON response t·ª´ Groq/GPT-OSS
        
        Args:
            groq_response: Response t·ª´ Groq API
            
        Returns:
            Dict ch·ª©a th√¥ng tin cƒÉn h·ªô ho·∫∑c None n·∫øu l·ªói
        """
        try:
            # Clean response ƒë·ªÉ l·∫•y JSON
            response_clean = groq_response.strip()
            
            # Log raw response ƒë·ªÉ debug
            logger.info(f"Raw GPT-OSS response: {response_clean[:300]}...")
            
            # T√¨m JSON trong response (c√≥ th·ªÉ c√≥ text kh√°c)
            start_idx = response_clean.find('{')
            end_idx = response_clean.rfind('}')
            
            if start_idx == -1 or end_idx == -1:
                logger.error("No JSON found in GPT-OSS response")
                logger.error(f"Full response: {response_clean}")
                return None
            
            json_str = response_clean[start_idx:end_idx + 1]
            logger.info(f"Extracted JSON: {json_str}")
            
            apartment_data = json.loads(json_str)
            
            # Validate v√† fix data types cho GPT-OSS
            apartment_data = PropertyService.validate_and_fix_apartment_data(apartment_data)
            
            logger.info(f"Successfully parsed GPT-OSS response: {len(apartment_data)} fields")
            return apartment_data
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {e}")
            logger.error(f"Raw response: {groq_response[:500]}...")
            
            # Th·ª≠ parse l·∫°i v·ªõi m·ªôt s·ªë fix c∆° b·∫£n cho GPT-OSS
            try:
                # Fix common JSON issues v·ªõi GPT-OSS
                fixed_response = response_clean
                
                # Fix c√°c l·ªói ph·ªï bi·∫øn
                fixes = [
                    ('"property_group": "S401"', '"property_group": 401'),
                    ('"unit_axis', '"unit_axis"'),
                    ('"unit_code', '"unit_code"'),
                    ('"price": "3.2 t·ª∑"', '"price": 3200000000'),
                    ('"area_gross": "85m2"', '"area_gross": 85'),
                    ('"num_bedrooms": "2PN"', '"num_bedrooms": 2'),
                    ('"num_bathrooms": "2WC"', '"num_bathrooms": 2'),
                ]
                
                for old, new in fixes:
                    fixed_response = fixed_response.replace(old, new)
                
                # T√¨m JSON l·∫°i
                start_idx = fixed_response.find('{')
                end_idx = fixed_response.rfind('}')
                
                if start_idx != -1 and end_idx != -1:
                    json_str = fixed_response[start_idx:end_idx + 1]
                    apartment_data = json.loads(json_str)
                    apartment_data = PropertyService.validate_and_fix_apartment_data(apartment_data)
                    logger.info("Successfully parsed after fixing JSON")
                    return apartment_data
                    
            except Exception as fix_error:
                logger.error(f"Failed to fix JSON: {fix_error}")
            
            return None
        except Exception as e:
            logger.error(f"Error parsing GPT-OSS response: {e}")
            return None
    
    def map_unit_type_to_id(self, unit_type_name) -> Optional[int]:
        """
        Map unit type name sang ID
        
        Args:
            unit_type_name: T√™n lo·∫°i cƒÉn h·ªô (c√≥ th·ªÉ l√† string ho·∫∑c int)
            
        Returns:
            ID t∆∞∆°ng ·ª©ng ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        return self.warehouse_service.map_unit_type_to_id(unit_type_name)
    
    def insert_apartment_via_api(self, apartment_data: Dict) -> bool:
        """
        Insert apartment v√†o warehouse database th√¥ng qua API
        
        Args:
            apartment_data: D·ªØ li·ªáu cƒÉn h·ªô t·ª´ Groq
            
        Returns:
            True n·∫øu th√†nh c√¥ng, False n·∫øu l·ªói
        """
        return self.warehouse_service.insert_apartment_via_api(apartment_data)
    
    def update_message_warehouse_id(self, message_id: int, warehouse_id: int) -> bool:
        """
        C·∫≠p nh·∫≠t warehouse_id c·ªßa tin nh·∫Øn sau khi x·ª≠ l√Ω v·ªõi retry mechanism
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn
            warehouse_id: ID c·ªßa apartment trong warehouse database
            
        Returns:
            True n·∫øu c·∫≠p nh·∫≠t th√†nh c√¥ng, False n·∫øu l·ªói
        """
        max_retries = 3
        retry_delay = 1
        
        for attempt in range(max_retries):
            connection = None
            try:
                logger.info(f"Updating message {message_id} warehouse_id to {warehouse_id} (attempt {attempt + 1}/{max_retries})")
                
                with zalo_app.app_context():
                    connection = self.get_zalo_db_connection()
                    if not connection:
                        logger.error(f"No database connection available (attempt {attempt + 1})")
                        continue
                
                from sqlalchemy import text
                query = text("""
                UPDATE zalo_received_messages 
                SET warehouse_id = :warehouse_id 
                WHERE id = :message_id
                """)
                
                connection.execute(query, {"warehouse_id": warehouse_id, "message_id": message_id})
                connection.commit()
                
                logger.info(f"‚úÖ Updated message {message_id} warehouse_id to {warehouse_id}")
                return True
                
            except Exception as e:
                logger.error(f"‚ùå Error updating message warehouse_id (attempt {attempt + 1}): {e}")
                logger.error(f"Error type: {type(e)}")
                
                if attempt < max_retries - 1:
                    logger.info(f"Retrying in {retry_delay} seconds...")
                    time.sleep(retry_delay)
                    retry_delay *= 2  # Exponential backoff
                else:
                    logger.error("‚ùå Failed to update message warehouse_id after all retries")
                return False
                    
            finally:
                if connection:
                    try:
                        connection.close()
                    except Exception as close_error:
                        logger.warning(f"Warning: Error closing connection: {close_error}")
        
        return False
    
    def process_messages_batch(self, limit: int = 20):
        """X·ª≠ l√Ω m·ªôt batch tin nh·∫Øn"""
        logger.info(f"Starting message batch processing (limit: {limit})...")
        
        # L·∫•y tin nh·∫Øn ch∆∞a x·ª≠ l√Ω
        messages = self.get_unprocessed_messages(limit=limit)
        
        if not messages:
            logger.info("No unprocessed messages found")
            return 0, 0
        
        processed_count = 0
        error_count = 0
        
        for message in messages:
            try:
                message_id = message['id']
                content = message['content']
                
                logger.info(f"Processing message {message_id}")
                
                # G·ª≠i t·ªõi Groq ƒë·ªÉ b√≥c t√°ch th√¥ng tin
                groq_result = self.process_message_with_groq(content)
                
                if groq_result:
                    logger.info(f"Groq result for message {message_id}: {groq_result[:100]}...")
                    
                    # Parse JSON t·ª´ Groq response
                    apartment_data = self.parse_groq_response(groq_result)
                    
                    if apartment_data:
                        # Insert/update v√†o warehouse database
                        warehouse_success = self.insert_apartment_via_api(apartment_data)
                        
                        if warehouse_success:
                            # Ch·ªâ c·∫≠p nh·∫≠t warehouse_id c·ªßa tin nh·∫Øn sau khi x·ª≠ l√Ω warehouse th√†nh c√¥ng
                            if self.update_message_warehouse_id(message_id, warehouse_success):
                                processed_count += 1
                                logger.info(f"Successfully processed message {message_id} with warehouse_id {warehouse_success}")
                            else:
                                error_count += 1
                                logger.error(f"Failed to update message {message_id} warehouse_id")
                        else:
                            error_count += 1
                            logger.error(f"Failed to insert/update apartment for message {message_id}")
                    else:
                        error_count += 1
                        logger.error(f"Failed to parse Groq response for message {message_id}")
                else:
                    logger.error(f"Failed to process message {message_id} with Groq")
                    error_count += 1
                    
            except Exception as e:
                logger.error(f"Error processing message {message.get('id', 'unknown')}: {e}")
                error_count += 1
        
        logger.info(f"Batch processing completed. Processed: {processed_count}, Errors: {error_count}")
        return processed_count, error_count
    
    def run_test_mode(self, limit: int = 50):
        """Ch·∫ø ƒë·ªô test - ch·∫°y m·ªôt s·ªë tin nh·∫Øn ƒë·∫ßu ƒë·ªÉ th·ª≠"""
        logger.info(f"üß™ Running in TEST mode - processing {limit} messages")
        
        start_time = time.time()
        processed_count, error_count = self.process_messages_batch(limit=limit)
        elapsed_time = time.time() - start_time
        
        logger.info(f"‚úÖ TEST mode completed in {elapsed_time:.2f}s")
        logger.info(f"üìä Results: {processed_count} processed, {error_count} errors")
        
        return processed_count, error_count
    
    def get_message_by_id(self, message_id: int) -> Optional[Dict]:
        """
        L·∫•y tin nh·∫Øn theo ID
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn c·∫ßn l·∫•y
            
        Returns:
            Dict ch·ª©a th√¥ng tin tin nh·∫Øn ho·∫∑c None n·∫øu kh√¥ng t√¨m th·∫•y
        """
        try:
            logger.info(f"üîç Fetching message with ID: {message_id}")
            
            with zalo_app.app_context():
                connection = self.get_zalo_db_connection()
                if not connection:
                    logger.error("‚ùå No database connection available")
                    return None
                
                from sqlalchemy import text
                
                query = text("""
                SELECT id, session_id, config_id, sender_id, sender_name, 
                       content, thread_id, thread_type, received_at, 
                       status_push_kafka, warehouse_id, reply_quote,
                       content_hash, added_document_chunks
                FROM zalo_received_messages 
                WHERE id = :message_id
                """)
                
                result = connection.execute(query, {"message_id": message_id})
                row = result.fetchone()
                
                if row:
                    message_data = dict(row._mapping)
                    logger.info(f"‚úÖ Found message {message_id}: {message_data.get('content', '')[:100]}...")
                    return message_data
                else:
                    logger.warning(f"‚ùå Message with ID {message_id} not found")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå Error fetching message {message_id}: {e}")
            return None
        finally:
            if connection:
                connection.close()
    
    def run_test_one_mode(self, message_id: int, real_insert: bool = False):
        """
        Ch·∫ø ƒë·ªô test one - test m·ªôt tin nh·∫Øn c·ª• th·ªÉ theo ID
        
        Args:
            message_id: ID c·ªßa tin nh·∫Øn c·∫ßn test
            real_insert: N·∫øu True, s·∫Ω th·ª±c s·ª± insert v√†o warehouse v√† c·∫≠p nh·∫≠t warehouse_id
        """
        mode_text = "REAL INSERT" if real_insert else "TEST MODE"
        logger.info(f"üß™ Running in TEST-ONE mode ({mode_text}) - processing message ID: {message_id}")
        
        start_time = time.time()
        
        try:
            # L·∫•y tin nh·∫Øn theo ID
            message = self.get_message_by_id(message_id)
            
            if not message:
                logger.error(f"‚ùå Message with ID {message_id} not found")
                return None, "Message not found"
            
            content = message['content']
            current_warehouse_id = message.get('warehouse_id')
            
            logger.info(f"üìù Message content: {content}")
            if current_warehouse_id:
                logger.info(f"üîÑ Message already has warehouse_id: {current_warehouse_id} - will replace")
            else:
                logger.info(f"üÜï Message has no warehouse_id - will create new")
            
            # G·ª≠i t·ªõi Groq ƒë·ªÉ b√≥c t√°ch th√¥ng tin
            logger.info("ü§ñ Processing with Groq...")
            groq_result = self.process_message_with_groq(content)
            
            
            if groq_result:
                logger.info(f"‚úÖ Groq result: {groq_result}")
                
                # Parse JSON t·ª´ Groq response
                apartment_data = self.parse_groq_response(groq_result)
                
                if apartment_data:
                    logger.info(f"üìä Parsed apartment data: {apartment_data}")
                    
                    # Insert/update v√†o warehouse database
                    if current_warehouse_id:
                        logger.info(f"üîÑ Replacing existing apartment (ID: {current_warehouse_id})...")
                    else:
                        logger.info("üè† Creating new apartment...")
                    
                    warehouse_result = self.insert_apartment_via_api(apartment_data)
                    
                    if warehouse_result:
                        logger.info("‚úÖ Warehouse insert/update successful")
                        
                        # Ch·ªâ c·∫≠p nh·∫≠t warehouse_id khi real_insert=True
                        if real_insert and isinstance(warehouse_result, int):
                            if current_warehouse_id:
                                logger.info(f"üîÑ Replacing warehouse_id from {current_warehouse_id} to {warehouse_result} for message {message_id}")
                            else:
                                logger.info(f"üÜï Setting warehouse_id {warehouse_result} for message {message_id}")
                            
                            update_success = self.update_message_warehouse_id(message_id, warehouse_result)
                            
                            if update_success:
                                logger.info(f"‚úÖ Successfully updated warehouse_id for message {message_id}")
                            else:
                                logger.error(f"‚ùå Failed to update warehouse_id for message {message_id}")
                        elif not real_insert:
                            logger.info("‚ÑπÔ∏è  Test mode - warehouse_id not updated to database")
                        
                        result = {
                            'message_id': message_id,
                            'message_content': content,
                            'groq_result': groq_result,
                            'parsed_data': apartment_data,
                            'warehouse_success': True,
                            'apartment_id': warehouse_result if isinstance(warehouse_result, int) else None,
                            'real_insert': real_insert,
                            'replaced': current_warehouse_id is not None,
                            'previous_warehouse_id': current_warehouse_id
                        }
                    else:
                        logger.error("‚ùå Warehouse insert/update failed")
                        result = {
                            'message_id': message_id,
                            'message_content': content,
                            'groq_result': groq_result,
                            'parsed_data': apartment_data,
                            'warehouse_success': False,
                            'error': 'Warehouse insert/update failed'
                        }
                else:
                    logger.error("‚ùå Failed to parse Groq response")
                    result = {
                        'message_id': message_id,
                        'message_content': content,
                        'groq_result': groq_result,
                        'parsed_data': None,
                        'warehouse_success': False,
                        'error': 'Failed to parse Groq response'
                    }
            else:
                logger.error("‚ùå Failed to process message with Groq")
                result = {
                    'message_id': message_id,
                    'message_content': content,
                    'groq_result': None,
                    'parsed_data': None,
                    'warehouse_success': False,
                    'error': 'Failed to process with Groq'
                }
            
            elapsed_time = time.time() - start_time
            logger.info(f"‚úÖ TEST-ONE mode completed in {elapsed_time:.2f}s")
            
            return result, None
            
        except Exception as e:
            logger.error(f"‚ùå Error in test-one mode: {e}")
            return None, str(e)
    
    def run_batch_mode(self):
        """Ch·∫ø ƒë·ªô batch - ch·∫°y t·∫•t c·∫£ tin nh·∫Øn t·ª´ tr∆∞·ªõc ƒë·∫øn nay"""
        logger.info("üì¶ Running in BATCH mode - processing ALL unprocessed messages")
        
        total_processed = 0
        total_errors = 0
        batch_size = 100  # X·ª≠ l√Ω t·ª´ng batch 100 tin nh·∫Øn
        batch_count = 0
        
        start_time = time.time()
        
        while True:
            batch_count += 1
            logger.info(f"Processing batch {batch_count} (size: {batch_size})")
            
            processed_count, error_count = self.process_messages_batch(limit=batch_size)
            
            total_processed += processed_count
            total_errors += error_count
            
            # N·∫øu kh√¥ng c√≥ tin nh·∫Øn n√†o ƒë∆∞·ª£c x·ª≠ l√Ω, d·ª´ng l·∫°i
            if processed_count == 0:
                break
                
            logger.info(f"Batch {batch_count} completed: {processed_count} processed, {error_count} errors")
        
        elapsed_time = time.time() - start_time
        
        logger.info(f"‚úÖ BATCH mode completed in {elapsed_time:.2f}s")
        logger.info(f"üìä Total results: {total_processed} processed, {total_errors} errors across {batch_count} batches")
        
        return total_processed, total_errors
    
    def run_scheduler_mode(self):
        """Ch·∫ø ƒë·ªô scheduler - ch·∫°y ƒë·ªãnh k·ª≥ nh∆∞ hi·ªán t·∫°i"""
        logger.info(f"‚è∞ Running in SCHEDULER mode (interval: {self.interval//60} minutes)")
        
        while self.is_running:
            try:
                start_time = time.time()
                
                # X·ª≠ l√Ω batch tin nh·∫Øn
                self.process_messages_batch(limit=20)
                
                # T√≠nh th·ªùi gian c√≤n l·∫°i ƒë·ªÉ sleep
                elapsed_time = time.time() - start_time
                sleep_time = max(0, self.interval - elapsed_time)
                
                logger.info(f"Processing completed in {elapsed_time:.2f}s. Sleeping for {sleep_time/60:.1f} minutes")
                
                # Sleep v·ªõi ki·ªÉm tra is_running ƒë·ªÉ c√≥ th·ªÉ d·ª´ng nhanh
                for _ in range(int(sleep_time)):
                    if not self.is_running:
                        break
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"Error in scheduler: {e}")
                # Sleep 60 gi√¢y n·∫øu c√≥ l·ªói ƒë·ªÉ tr√°nh spam
                time.sleep(60)
    
    def run_scheduler(self):
        """Ch·∫°y scheduler ƒë·ªãnh k·ª≥ (legacy method)"""
        self.run_scheduler_mode()
    
    def start(self):
        """B·∫Øt ƒë·∫ßu service"""
        if self.is_running:
            logger.warning("Service is already running")
            return
        
        # Ki·ªÉm tra xem schedule c√≥ ƒë∆∞·ª£c enable kh√¥ng
        if not self.schedule_enabled:
            logger.info("ZaloMessageProcessor schedule is disabled (ZALO_MESSAGE_PROCESSOR_SCHEDULE=0)")
            return
        
        self.is_running = True
        self.thread = threading.Thread(target=self.run_scheduler, daemon=True)
        self.thread.start()
        
        logger.info(f"ZaloMessageProcessor service started (interval: {self.interval//60} minutes)")
    
    def stop(self):
        """D·ª´ng service"""
        if not self.is_running:
            logger.warning("Service is not running")
            return
        
        logger.info("üõë Stopping ZaloMessageProcessor service...")
        self.is_running = False
        
        if self.thread and self.thread.is_alive():
            logger.info("‚è≥ Waiting for thread to finish...")
            self.thread.join(timeout=10)  # TƒÉng timeout l√™n 10 gi√¢y
            
            if self.thread.is_alive():
                logger.warning("‚ö†Ô∏è Thread did not stop gracefully, forcing shutdown")
            else:
                logger.info("‚úÖ Thread stopped gracefully")
        
        logger.info("üõë ZaloMessageProcessor service stopped")
    
    def get_status(self) -> Dict:
        """L·∫•y tr·∫°ng th√°i service"""
        return {
            'is_running': self.is_running,
            'thread_alive': self.thread.is_alive() if self.thread else False,
            'interval': self.interval,
            'interval_minutes': self.interval // 60,
            'schedule_enabled': self.schedule_enabled,
            'started_at': datetime.now().isoformat() if self.is_running else None
        }


# Global instance
zalo_processor = ZaloMessageProcessor()

def main():
    """Main function v·ªõi command line arguments"""
    parser = argparse.ArgumentParser(description='Zalo Message Processor Service')
    parser.add_argument('--mode', choices=['test', 'test-one', 'batch', 'scheduler'], default='scheduler',
                       help='Ch·∫ø ƒë·ªô ch·∫°y: test (50 tin nh·∫Øn), test-one (1 tin nh·∫Øn theo ID), batch (t·∫•t c·∫£), scheduler (ƒë·ªãnh k·ª≥)')
    parser.add_argument('--limit', type=int, default=50,
                       help='S·ªë l∆∞·ª£ng tin nh·∫Øn cho ch·∫ø ƒë·ªô test (default: 50)')
    parser.add_argument('--message-id', type=int,
                       help='ID c·ªßa tin nh·∫Øn c·∫ßn test (ch·ªâ d√πng v·ªõi mode test-one)')
    
    args = parser.parse_args()
    
    try:
        if args.mode == 'test':
            logger.info(f"üß™ Starting ZaloMessageProcessor in TEST mode (limit: {args.limit})")
            zalo_processor.run_test_mode(limit=args.limit)
            
        elif args.mode == 'test-one':
            if not args.message_id:
                logger.error("‚ùå --message-id is required for test-one mode")
                return
            logger.info(f"üß™ Starting ZaloMessageProcessor in TEST-ONE mode (message ID: {args.message_id})")
            result, error = zalo_processor.run_test_one_mode(args.message_id)
            
            if error:
                logger.error(f"‚ùå Test failed: {error}")
            else:
                logger.info("‚úÖ Test completed successfully")
                logger.info(f"üìä Result: {result}")
            
        elif args.mode == 'batch':
            logger.info("üì¶ Starting ZaloMessageProcessor in BATCH mode")
            zalo_processor.run_batch_mode()
            
        elif args.mode == 'scheduler':
            logger.info("‚è∞ Starting ZaloMessageProcessor in SCHEDULER mode")
            zalo_processor.start()
            
            # Gi·ªØ service ch·∫°y
            while zalo_processor.is_running:
                time.sleep(1)
                
    except KeyboardInterrupt:
        logger.info("Received interrupt signal, stopping service...")
        if args.mode == 'scheduler':
            zalo_processor.stop()
    except Exception as e:
        logger.error(f"Service error: {e}")
        if args.mode == 'scheduler':
            zalo_processor.stop()

if __name__ == "__main__":
    main()
