#!/usr/bin/env python3
"""
Test script cho vector search ti·∫øng Vi·ªát
"""

import os
import json
import requests
from dotenv import load_dotenv
from pymilvus import connections, Collection, utility
from sentence_transformers import SentenceTransformer

# Load environment variables
load_dotenv()

def get_auth_token():
    """L·∫•y JWT token"""
    login_data = {
        "username": "user",
        "password": "user123"
    }
    
    response = requests.post("http://localhost:5000/auth/login", json=login_data)
    
    if response.status_code == 200:
        return response.json().get('access_token')
    else:
        print(f"‚ùå Login failed: {response.text}")
        return None

def test_vietnamese_embedding():
    """Test embedding v·ªõi ti·∫øng Vi·ªát"""
    print("üáªüá≥ Testing Vietnamese embedding...")
    
    try:
        model_name = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        model = SentenceTransformer(model_name)
        
        # Test sentences ti·∫øng Vi·ªát
        vietnamese_texts = [
            "H·ªçc m√°y l√† m·ªôt nh√°nh c·ªßa tr√≠ tu·ªá nh√¢n t·∫°o",
            "Thu·∫≠t to√°n h·ªçc m√°y r·∫•t m·∫°nh m·∫Ω",
            "X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n",
            "Tr√≠ tu·ªá nh√¢n t·∫°o v√† machine learning",
            "Deep learning v√† neural networks"
        ]
        
        print(f"‚úÖ Model loaded: {model_name}")
        
        for i, text in enumerate(vietnamese_texts, 1):
            embedding = model.encode(text)
            print(f"  {i}. '{text[:50]}...' -> Dimension: {len(embedding)}")
        
        return model
    except Exception as e:
        print(f"‚ùå Vietnamese embedding failed: {e}")
        return None

def test_vietnamese_similarity():
    """Test similarity gi·ªØa ti·∫øng Vi·ªát v√† ti·∫øng Anh"""
    print("\nüîç Testing Vietnamese-English similarity...")
    
    try:
        model_name = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        model = SentenceTransformer(model_name)
        
        # Test pairs
        test_pairs = [
            ("h·ªçc m√°y", "machine learning"),
            ("tr√≠ tu·ªá nh√¢n t·∫°o", "artificial intelligence"),
            ("x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n", "natural language processing"),
            ("thu·∫≠t to√°n", "algorithm"),
            ("d·ªØ li·ªáu", "data")
        ]
        
        from sklearn.metrics.pairwise import cosine_similarity
        import numpy as np
        
        print("üìä Similarity scores:")
        for vi_text, en_text in test_pairs:
            vi_embedding = model.encode(vi_text).reshape(1, -1)
            en_embedding = model.encode(en_text).reshape(1, -1)
            
            similarity = cosine_similarity(vi_embedding, en_embedding)[0][0]
            print(f"  '{vi_text}' vs '{en_text}': {similarity:.3f}")
        
        return True
    except Exception as e:
        print(f"‚ùå Similarity test failed: {e}")
        return False

def test_vietnamese_crawl():
    """Test crawl website ti·∫øng Vi·ªát"""
    print("\nüï∑Ô∏è Testing Vietnamese website crawl...")
    
    token = get_auth_token()
    if not token:
        return False
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    # Test v·ªõi website ti·∫øng Vi·ªát
    vietnamese_sites = [
        "https://vi.wikipedia.org/wiki/H·ªçc_m√°y",
        "https://vi.wikipedia.org/wiki/Tr√≠_tu·ªá_nh√¢n_t·∫°o",
        "https://vi.wikipedia.org/wiki/X·ª≠_l√Ω_ng√¥n_ng·ªØ_t·ª±_nhi√™n"
    ]
    
    for site in vietnamese_sites:
        try:
            print(f"üì• Crawling: {site}")
            response = requests.post(
                "http://localhost:5000/user/crawls",
                json={"link": site, "crawl_tool": "firecrawl"},
                headers=headers
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Success: {result.get('content_length', 0)} characters")
            else:
                print(f"‚ùå Failed: {response.text}")
                
        except Exception as e:
            print(f"‚ùå Error crawling {site}: {e}")
    
    return True

def test_vietnamese_search():
    """Test search v·ªõi query ti·∫øng Vi·ªát"""
    print("\nüîç Testing Vietnamese search...")
    
    token = get_auth_token()
    if not token:
        return False
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    # Test queries ti·∫øng Vi·ªát
    vietnamese_queries = [
        "h·ªçc m√°y",
        "tr√≠ tu·ªá nh√¢n t·∫°o", 
        "x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n",
        "thu·∫≠t to√°n",
        "deep learning",
        "neural networks"
    ]
    
    for query in vietnamese_queries:
        try:
            print(f"\nüîç Searching for: '{query}'")
            
            search_data = {
                "query": query,
                "top_k": 3
            }
            
            response = requests.post(
                "http://localhost:5000/user/search",
                json=search_data,
                headers=headers
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Found {result.get('total_results', 0)} results")
                
                results = result.get('results', [])
                for i, res in enumerate(results, 1):
                    score = res.get('similarity_score', 0)
                    content = res.get('content', '')[:100]
                    print(f"  {i}. Score: {score:.3f} - {content}...")
            else:
                print(f"‚ùå Search failed: {response.text}")
                
        except Exception as e:
            print(f"‚ùå Error searching '{query}': {e}")
    
    return True

def test_mixed_language_search():
    """Test search v·ªõi c·∫£ ti·∫øng Vi·ªát v√† ti·∫øng Anh"""
    print("\nüåç Testing mixed language search...")
    
    token = get_auth_token()
    if not token:
        return False
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    # Test v·ªõi query h·ªón h·ª£p
    mixed_queries = [
        "machine learning v√† h·ªçc m√°y",
        "AI tr√≠ tu·ªá nh√¢n t·∫°o",
        "NLP x·ª≠ l√Ω ng√¥n ng·ªØ",
        "deep learning h·ªçc s√¢u",
        "neural networks m·∫°ng n∆°-ron"
    ]
    
    for query in mixed_queries:
        try:
            print(f"\nüîç Mixed query: '{query}'")
            
            search_data = {
                "query": query,
                "top_k": 3
            }
            
            response = requests.post(
                "http://localhost:5000/user/search",
                json=search_data,
                headers=headers
            )
            
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ Found {result.get('total_results', 0)} results")
                
                results = result.get('results', [])
                for i, res in enumerate(results, 1):
                    score = res.get('similarity_score', 0)
                    content = res.get('content', '')[:100]
                    print(f"  {i}. Score: {score:.3f} - {content}...")
            else:
                print(f"‚ùå Search failed: {response.text}")
                
        except Exception as e:
            print(f"‚ùå Error searching '{query}': {e}")
    
    return True

def main():
    """Main test function"""
    print("üáªüá≥ Vietnamese Vector Search Test")
    print("="*60)
    
    # Test t·ª´ng component
    tests = [
        ("Vietnamese Embedding", test_vietnamese_embedding),
        ("Vietnamese Similarity", test_vietnamese_similarity),
        ("Vietnamese Crawl", test_vietnamese_crawl),
        ("Vietnamese Search", test_vietnamese_search),
        ("Mixed Language Search", test_mixed_language_search)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results[test_name] = False
    
    # Summary
    print(f"\n{'='*60}")
    print("üìã VIETNAMESE TEST SUMMARY")
    print("="*60)
    
    for test_name, result in results.items():
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{test_name}: {status}")
    
    # Recommendations
    print(f"\nüí° VIETNAMESE OPTIMIZATION TIPS")
    print("="*60)
    
    print("1. üéØ Use Vietnamese queries:")
    print("   - 'h·ªçc m√°y' instead of 'machine learning'")
    print("   - 'tr√≠ tu·ªá nh√¢n t·∫°o' instead of 'artificial intelligence'")
    
    print("\n2. üåç Mixed language support:")
    print("   - Model supports both Vietnamese and English")
    print("   - Can search with mixed queries")
    
    print("\n3. üìö Vietnamese content sources:")
    print("   - Wikipedia ti·∫øng Vi·ªát")
    print("   - Vietnamese tech blogs")
    print("   - Vietnamese documentation")

if __name__ == "__main__":
    main() 